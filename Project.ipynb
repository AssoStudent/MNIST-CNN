{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IERG4160 2023-24 Spring: Individual Project - Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0 Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import random\n",
    "import string\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset, DataLoader, ConcatDataset, Subset\n",
    "from torch.optim.optimizer import (Optimizer, required, _use_grad_for_differentiable, _default_to_fused_or_foreach,\n",
    "                        _differentiable_doc, _foreach_doc, _maximize_doc)\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilize GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download MINST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Download Dataset\n",
    "MNIST_train_dataset = MNIST(root='./Datasets', train=True, download=True, transform=transforms.ToTensor())\n",
    "MNIST_test_dataset = MNIST(root='./Datasets', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the dataset\n",
    "print(\"=== Raw Data Samples from the MNIST Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_train_dataset[i]\n",
    "    image = image.squeeze().numpy()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"=== Raw Data Samples from the MNIST Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_test_dataset[i]\n",
    "    image = image.squeeze().numpy()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helping Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global train_start_time\n",
    "\n",
    "def load_image(filename):\n",
    "  im_pil = Image.open(filename)\n",
    "  im = np.array(im_pil).astype(np.float32) / 255\n",
    "  return im\n",
    "\n",
    "def convert_to_list(input_list):\n",
    "    if not isinstance(input_list, list):\n",
    "        input_list = [input_list]\n",
    "    return input_list\n",
    "\n",
    "def plot_time_history(time_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Culminative Time Used\", title_name=\"Time History\"):\n",
    "    time_history_list = convert_to_list(time_history_list)\n",
    "    for i, time_history in enumerate(time_history_list):\n",
    "        plt.plot(time_history, label=f\"Time History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(time_history_list) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_time_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_history(train_loss_history_list=[], test_loss_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Loss\", title_name=\"Loss History\"):\n",
    "    train_loss_history_list = convert_to_list(train_loss_history_list)\n",
    "    test_loss_history_list = convert_to_list(test_loss_history_list)\n",
    "    for i, train_loss_history in enumerate(train_loss_history_list):\n",
    "        plt.plot(train_loss_history, label=f\"Train Loss History {i+1}\")\n",
    "    for i, test_loss_history in enumerate(test_loss_history_list):\n",
    "        plt.plot(test_loss_history, label=f\"Test Loss History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_loss_history_list) + len(test_loss_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_loss_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_history(train_accuracy_history_list=[], test_accuracy_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Accuracy\", title_name=\"Accuracy History\"):\n",
    "    train_accuracy_history_list = convert_to_list(train_accuracy_history_list)\n",
    "    test_accuracy_history_list = convert_to_list(test_accuracy_history_list)\n",
    "    for i, train_accuracy_history in enumerate(train_accuracy_history_list):\n",
    "        plt.plot(train_accuracy_history, label=f\"Train Accuracy History {i+1}\")\n",
    "    for i, test_accuracy_history in enumerate(test_accuracy_history_list):\n",
    "        plt.plot(test_accuracy_history, label=f\"Test Accuracy History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_accuracy_history_list) + len(test_accuracy_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_accuracy_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_history(train_error_history_list=[], test_error_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Error\", title_name=\"Error History\"):\n",
    "    train_error_history_list = convert_to_list(train_error_history_list)\n",
    "    test_error_history_list = convert_to_list(test_error_history_list)\n",
    "    for i, train_error_history in enumerate(train_error_history_list):\n",
    "        plt.plot(train_error_history, label=f\"Train Error History {i+1}\")\n",
    "    for i, test_error_history in enumerate(test_error_history_list):\n",
    "        plt.plot(test_error_history, label=f\"Test Error History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_error_history_list) + len(test_error_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_error_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_time_history_single(time_history, save=True, x_label_name=\"Epochs\", y_label_name=\"Culminative Time Used\", title_name=\"Time History\"):\n",
    "    plt.plot(time_history, label=f\"Time History\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_time_history_single_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_history_single(train_loss_history, test_loss_history, save=True, x_label_name=\"Epochs\", y_label_name=\"Loss\", title_name=\"Loss History\"):\n",
    "    plt.plot(train_loss_history, label=f\"Train Loss History\")\n",
    "    plt.plot(test_loss_history, label=f\"Test Loss History\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_loss_history_single_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_history_single(train_accuracy_history, test_accuracy_history, save=True, x_label_name=\"Epochs\", y_label_name=\"Accuracy\", title_name=\"Accuracy History\"):\n",
    "    plt.plot(train_accuracy_history, label=f\"Train Accuracy History\")\n",
    "    plt.plot(test_accuracy_history, label=f\"Test Accuracy History\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_accuracy_history_single_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_history_single(train_error_history, test_error_history, save=True, x_label_name=\"Epochs\", y_label_name=\"Error\", title_name=\"Error History\"):\n",
    "    plt.plot(train_error_history, label=f\"Train Error History\")\n",
    "    plt.plot(test_error_history, label=f\"Test Error History\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_error_history_single_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def get_accuracy(outputs, labels):\n",
    "    with torch.no_grad():\n",
    "        if outputs.dim() > 1:\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "        else:\n",
    "            predictions = outputs\n",
    "        return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n",
    "\n",
    "def get_error(outputs, labels):\n",
    "    with torch.no_grad():\n",
    "        if outputs.dim() > 1:\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "        else:\n",
    "            predictions = outputs\n",
    "        return torch.tensor(torch.sum(predictions != labels).item() / len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 Task 1 Neural Network Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterate Algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_simple(model, dataloader, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in dataloader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "    return loss_average, accuracy_average, error_average\n",
    "\n",
    "def iterate_model_simple(model, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, test_dataloader=None, include_intial_history=False):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = []\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    if include_intial_history is True:\n",
    "        loss, accuracy, error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        loss_history.append(loss)\n",
    "        accuracy_history.append(accuracy)\n",
    "        error_history.append(error)\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch, (features, labels) in enumerate(dataloader):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss_average:.16f}, Train Accuracy: {accuracy_average:.16f}, Train Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "    if test_dataloader is not None:\n",
    "        return loss_history, accuracy_history, error_history, time_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "    return loss_history, accuracy_history, error_history, time_history\n",
    "\n",
    "def train_neural_network_model(model, train_dataloader, test_dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True, save_path_str=\"MNIST_CNN\", save_file_extra_information=\"\"):\n",
    "    if test_dataloader is not None:\n",
    "        train_loss_history, train_accuracy_history, train_error_history, time_history, test_loss_history, test_accuracy_history, test_error_history = iterate_model_simple(model, train_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, test_dataloader, True)\n",
    "    else:\n",
    "        train_loss_history, train_accuracy_history, train_error_history, time_history = iterate_model_simple(model, train_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_{}_{}.npy\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, time_history=time_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history, extra_information=save_file_extra_information)\n",
    "        torch.save(model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "        logname = \"{}_{}_{}.txt\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(logname, 'wb') as f:\n",
    "            f.write(save_file_extra_information.encode('utf-8'))\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "    \n",
    "    return time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "def experiment_neural_network_model(train_dataset, test_dataset, modelClass, optimizerClass, train_func, epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, experiment_rounds = 1, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    epochs_list = convert_to_list(epochs_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "\n",
    "    time_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "    \n",
    "    for n in range(experiment_rounds):\n",
    "        experiment_id = experiment_id + 1\n",
    "        print(f'=== Training Experiment {experiment_id} ===')\n",
    "        print(f'number of epochs is {epochs_list[min(n, len(epochs_list) - 1)]}')\n",
    "        num_epochs = epochs_list[min(n, len(epochs_list) - 1)]\n",
    "        print(f'learning rate is {learning_rate_list[min(n, len(learning_rate_list) - 1)]}')\n",
    "        learning_rate = learning_rate_list[min(n, len(learning_rate_list) - 1)]\n",
    "        print(f'batch size is {batch_size_list[min(n, len(batch_size_list) - 1)]}')\n",
    "        batch_size = batch_size_list[min(n, len(batch_size_list) - 1)]\n",
    "        print(f'loss function is {loss_func_list[min(n, len(loss_func_list) - 1)]}')\n",
    "        loss_func = loss_func_list[min(n, len(loss_func_list) - 1)]\n",
    "        print(f'accuracy function is {accuracy_func_list[min(n, len(accuracy_func_list) - 1)]}')\n",
    "        accuracy_func = accuracy_func_list[min(n, len(accuracy_func_list) - 1)]\n",
    "        print(f'error function is {error_func_list[min(n, len(error_func_list) - 1)]}')\n",
    "        error_func = error_func_list[min(n, len(error_func_list) - 1)]\n",
    "        \n",
    "        model = modelClass().to(device)\n",
    "\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        optimizer = optimizerClass(model.parameters(), learning_rate)\n",
    "\n",
    "        save_path_str = f\"IERG4160_Project_{current_dataset_name}_E_{num_epochs}_lr_{learning_rate}_B_{batch_size}\"\n",
    "\n",
    "        global save_file_extra_information\n",
    "        save_file_extra_information = f\"\"\"\n",
    "        === {save_path_str} ===\n",
    "        IERG4160 Project Training\n",
    "        The experiment ID is: {experiment_id}\n",
    "        The train start time is: {train_start_time}\n",
    "        The dataset is: {current_dataset_name}\n",
    "\n",
    "        experiment_rounds = {experiment_rounds}\n",
    "\n",
    "        modelType = {modelClass.__name__}\n",
    "        optimizerType = {optimizerClass.__name__}\n",
    "\n",
    "        num_epochs_list = {epochs_list}\n",
    "        learning_rate_list = {learning_rate_list}\n",
    "        batch_size_list = {batch_size_list}\n",
    "        loss_func_list = {loss_func_list}\n",
    "        accuracy_func_list = {accuracy_func_list}\n",
    "        error_func_list = {error_func_list}\n",
    "\n",
    "        !-- Current Status --!\n",
    "        num_epochs = {num_epochs}\n",
    "        learning_rate = {learning_rate}\n",
    "        batch_size = {batch_size}\n",
    "        loss_func = {loss_func}\n",
    "        accuracy_func = {accuracy_func}\n",
    "        error_func = {error_func}\n",
    "        \"\"\"\n",
    "\n",
    "        time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_func(model, train_dataloader, test_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str, save_file_extra_information)\n",
    "\n",
    "        time_history_total.append(time_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# Load Dataset\n",
    "train_dataset = MNIST_train_dataset\n",
    "test_dataset = MNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"MNIST\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(7*7*32, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = MNIST_CNN_Model\n",
    "optimizerType = torch.optim.SGD\n",
    "train_func = train_neural_network_model\n",
    "\n",
    "num_epochs_list = 10\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "loss_func_list = torch.nn.CrossEntropyLoss()\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "experiment_neural_network_model(train_dataset, test_dataset, modelType, optimizerType, train_func, num_epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Task 2 U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST Noisy Dataset**\n",
    "\n",
    "Note: Remember in the noisy dataset label is a image, instead of a number in original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST Noisy\n",
    "noisy_sigma = 0.02\n",
    "\n",
    "def add_gaussian_noise(images, sigma):\n",
    "    noisy_images = images + sigma * np.random.normal(size = images.shape)\n",
    "    noisy_images = np.clip(noisy_images, 0.0, 1.0)\n",
    "    return noisy_images\n",
    "\n",
    "def convert_pure_image_array(images):\n",
    "    images = images.astype(np.float32)\n",
    "    images = np.squeeze(images)\n",
    "    images = images.reshape(images.shape[0], -1)\n",
    "    images = (images * 255).astype(np.uint8)\n",
    "    return images\n",
    "\n",
    "MNIST_train_dataset_noisy_image = []\n",
    "MNIST_train_dataset_noisy_label = []\n",
    "MNIST_test_dataset_noisy_image = []\n",
    "MNIST_test_dataset_noisy_label = []\n",
    "for image, _ in MNIST_train_dataset:\n",
    "    noisy_images = add_gaussian_noise(image.numpy() / 255.0, noisy_sigma)\n",
    "    noisy_images = convert_pure_image_array(noisy_images)\n",
    "    truth_images = convert_pure_image_array(image.numpy())\n",
    "    MNIST_train_dataset_noisy_image.append(noisy_images)\n",
    "    MNIST_train_dataset_noisy_label.append(truth_images)\n",
    "for image, _ in MNIST_test_dataset:\n",
    "    noisy_images = add_gaussian_noise(image.numpy() / 255.0, noisy_sigma)\n",
    "    noisy_images = convert_pure_image_array(noisy_images)\n",
    "    truth_images = convert_pure_image_array(image.numpy())\n",
    "    MNIST_test_dataset_noisy_image.append(noisy_images)\n",
    "    MNIST_test_dataset_noisy_label.append(truth_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNoisy(Dataset):\n",
    "    def __init__(self, data_sample, targets_sample, train=True, transform=None, target_transform=None):\n",
    "        self.train = train\n",
    "        self.data, self.targets = self._load_data(data_sample, targets_sample)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def _load_data(self, data_sample, targets_sample):\n",
    "        data = torch.tensor(data_sample)\n",
    "        targets = torch.tensor(targets_sample)\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        img = Image.fromarray(img.numpy(), mode=\"L\")\n",
    "        target = Image.fromarray(target.numpy(), mode=\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "MNIST_train_dataset_noisy = MNISTNoisy(MNIST_train_dataset_noisy_image, MNIST_train_dataset_noisy_label, train=True, transform=transforms.ToTensor(), target_transform=transforms.ToTensor())\n",
    "MNIST_test_dataset_noisy = MNISTNoisy(MNIST_test_dataset_noisy_image, MNIST_test_dataset_noisy_label, train=False, transform=transforms.ToTensor(), target_transform=transforms.ToTensor())\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = MNIST_train_dataset_noisy\n",
    "test_dataset = MNIST_test_dataset_noisy\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"MNIST Noisy\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the dataset\n",
    "print(\"=== Raw Data Samples from the MNIST Noisy Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_train_dataset_noisy[i]\n",
    "    print(\"Noisy Image:\")\n",
    "    image = image.numpy().squeeze()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Ground Truth Image:\")\n",
    "    label = label.numpy().squeeze()\n",
    "    plt.imshow(label, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "print(\"=== Raw Data Samples from the MNIST Noisy Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_test_dataset_noisy[i]\n",
    "    print(\"Noisy Image:\")\n",
    "    image = image.numpy().squeeze()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Ground Truth Image:\")\n",
    "    label = label.numpy().squeeze()\n",
    "    plt.imshow(label, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_UNet_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.up1 = torch.nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2)\n",
    "        self.conv4 = torch.nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.up2 = torch.nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2)\n",
    "        self.conv5 = torch.nn.Conv2d(48, 32, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        pool1_out = self.pool1(conv1_out)\n",
    "        conv2_out = self.conv2(pool1_out)\n",
    "        pool2_out = self.pool2(conv2_out)\n",
    "        conv3_out = self.conv3(pool2_out)\n",
    "        up1_out = self.up1(conv3_out)\n",
    "        cat1_out = torch.cat([up1_out, conv2_out], dim=1)\n",
    "        conv4_out = self.conv4(cat1_out)\n",
    "        up2_out = self.up2(conv4_out)\n",
    "        cat2_out = torch.cat([up2_out, conv1_out], dim=1)\n",
    "        conv5_out = self.conv5(cat2_out)\n",
    "        return conv5_out\n",
    "    \n",
    "class MNIST_UNet_Model_SingleChannel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.up1 = torch.nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2)\n",
    "        self.conv4 = torch.nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
    "        self.up2 = torch.nn.ConvTranspose2d(24, 24, kernel_size=2, stride=2)\n",
    "        self.conv5 = torch.nn.Conv2d(24, 8, kernel_size=3, padding=1)\n",
    "        self.conv6 = torch.nn.Conv2d(8, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        pool1_out = self.pool1(conv1_out)\n",
    "        conv2_out = self.conv2(pool1_out)\n",
    "        pool2_out = self.pool2(conv2_out)\n",
    "        conv3_out = self.conv3(pool2_out)\n",
    "        up1_out = self.up1(conv3_out)\n",
    "        cat1_out = torch.nn.cat([up1_out, conv2_out], dim=1)\n",
    "        conv4_out = self.conv4(cat1_out)\n",
    "        up2_out = self.up2(conv4_out)\n",
    "        cat2_out = torch.nn.cat([up2_out, conv1_out], dim=1)\n",
    "        conv5_out = self.conv5(cat2_out)\n",
    "        conv6_out = self.conv6(conv5_out)\n",
    "\n",
    "        return conv6_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = MNIST_UNet_Model\n",
    "optimizerType = torch.optim.SGD\n",
    "train_func = train_neural_network_model\n",
    "\n",
    "# Custom Parameters\n",
    "custom_image_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((16,16)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "custom_target_transform = transforms.Compose([\n",
    "    transforms.Resize((16,16)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset.transform = custom_image_transform\n",
    "train_dataset.target_transform = custom_target_transform\n",
    "test_dataset.transform = custom_image_transform\n",
    "test_dataset.target_transform = custom_target_transform\n",
    "#---------------------#\n",
    "\n",
    "num_epochs_list = 10\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 10\n",
    "loss_func_list = torch.nn.MSELoss()\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "experiment_neural_network_model(train_dataset, test_dataset, modelType, optimizerType, train_func, num_epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.1 Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Change the parameter manually here!! --- #\n",
    "predict_image_path = \"Test.png\"\n",
    "predict_model_path = \"IERG4160_Project_MNIST_E_10_lr_0.03_B_128_2024-03-30 18.36.57_1.npy_model_state_dict.pth\"\n",
    "predict_model_type = MNIST_CNN_Model\n",
    "predict_image_togrey = True\n",
    "#----------------------------------------------#\n",
    "\n",
    "predict_model = predict_model_type()\n",
    "predict_model.load_state_dict(torch.load(predict_model_path, map_location=device))\n",
    "\n",
    "if predict_image_togrey is True:\n",
    "    test_image = 1.0 - cv2.cvtColor(cv2.resize(load_image(predict_image_path), (28, 28)), cv2.COLOR_RGB2GRAY)\n",
    "else:\n",
    "    test_image = cv2.resize(load_image(predict_image_path), (28, 28))\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "\n",
    "test_image_torch = torch.Tensor(test_image[np.newaxis, np.newaxis])\n",
    "test_predicted_label_array = predict_model(test_image_torch).detach().numpy()[0, ...]\n",
    "print('The chances for predicted labels are: ', test_predicted_label_array)\n",
    "\n",
    "test_predicted_label = np.argmax(test_predicted_label_array)\n",
    "\n",
    "print('The predicted label is: ', test_predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.2 Training Performance Visulization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clear and Initialize Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time_history_total = []\n",
    "data_train_loss_history_total = []\n",
    "data_train_accuracy_history_total = []\n",
    "data_train_error_history_total = []\n",
    "data_test_loss_history_total = []\n",
    "data_test_accuracy_history_total = []\n",
    "data_test_error_history_total = []\n",
    "\n",
    "# Run this whenever you want to clear all appended data or initially load data!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data Manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Change the parameter manually here!! --- #\n",
    "filename_load_list = [\"IERG4160_Project_MNIST_E_10_lr_0.03_B_128_2024-03-30 18.36.57_1.npy\",\n",
    "                      \"\"]\n",
    "data_append_load = True\n",
    "#----------------------------------------------#\n",
    "\n",
    "for filename_load in filename_load_list:\n",
    "    print(\"============================================\")\n",
    "    print(\"*** Loading file...                     ***\")\n",
    "    print(\"============================================\")\n",
    "    try:\n",
    "        # Load the file\n",
    "        load_result = np.load(filename_load)\n",
    "        print('Result has been loaded from the file: ', filename_load)\n",
    "\n",
    "        # Load the attributes from the file\n",
    "        data_time_history = load_result['time_history']\n",
    "        data_train_loss_history = load_result['train_loss_history']\n",
    "        data_train_accuracy_history = load_result['train_accuracy_history']\n",
    "        data_train_error_history = load_result['train_error_history']\n",
    "        data_test_loss_history = load_result['test_loss_history']\n",
    "        data_test_accuracy_history = load_result['test_accuracy_history']\n",
    "        data_test_error_history = load_result['test_error_history']\n",
    "\n",
    "        print(\"=======Content of the File=======\")\n",
    "        print(load_result.files)\n",
    "\n",
    "        print(\"=======STATUS RESULT=======\")\n",
    "        print(\"Time History: \", data_time_history)\n",
    "\n",
    "        print(\"=======TRAIN RESULT=======\")\n",
    "        print(\"Train Loss History: \", data_train_loss_history)\n",
    "        print(\"Train Accuracy History: \", data_train_accuracy_history)\n",
    "        print(\"Train Error History: \", data_train_error_history)\n",
    "\n",
    "        print(\"=======TEST RESULT=======\")\n",
    "        print(\"Test Loss History: \", data_test_loss_history)\n",
    "        print(\"Test Accuracy History: \", data_test_accuracy_history)\n",
    "        print(\"Test Error History: \", data_test_error_history)\n",
    "\n",
    "        print(\"=======VISUALIZATION RESULT=======\")\n",
    "        #plot_time_history_single(data_time_history, save=False)\n",
    "        plot_loss_history_single(data_train_loss_history, data_test_loss_history, save=False)\n",
    "        plot_accuracy_history_single(data_train_accuracy_history, data_test_accuracy_history, save=False)\n",
    "        plot_error_history_single(data_train_error_history, data_test_error_history, save=False)\n",
    "\n",
    "        # Append the data\n",
    "        if data_append_load:\n",
    "            data_time_history_total.append(data_time_history)\n",
    "            data_train_loss_history_total.append(data_train_loss_history)\n",
    "            data_train_accuracy_history_total.append(data_train_accuracy_history)\n",
    "            data_train_error_history_total.append(data_train_error_history)\n",
    "            data_test_loss_history_total.append(data_test_loss_history)\n",
    "            data_test_accuracy_history_total.append(data_test_accuracy_history)\n",
    "            data_test_error_history_total.append(data_test_error_history)\n",
    "    except (FileNotFoundError, IOError):\n",
    "        print(\"Failed to load the file: \", filename_load)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot for Experiment Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Change the parameter manually here!! --- #\n",
    "plot_parameters_list = [1]\n",
    "plot_title_strings = \"\"\n",
    "plot_legend_strings = \"\"\n",
    "plot_save_fig_bool = False\n",
    "plot_show_train_bool = True\n",
    "plot_show_test_bool = False\n",
    "plot_log_scale = False\n",
    "#----------------------------------------------#\n",
    "\n",
    "plot_different_parameter_time_history = convert_to_list(data_time_history_total)\n",
    "for i, plot_time_history in enumerate(plot_different_parameter_time_history):\n",
    "    plt.plot(plot_time_history, label=f\"Time History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Culminative Time Used\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Culminative Time Used\")\n",
    "plt.title(\"Time History\" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_time_history_{plot_legend_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_parameter_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_loss_history in enumerate(plot_different_parameter_train_loss_history):\n",
    "        plt.plot(plot_train_loss_history, label=f\"Train Loss History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_loss_history in enumerate(plot_different_parameter_test_loss_history):\n",
    "        plt.plot(plot_test_loss_history, label=f\"Test Loss History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Loss\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History\" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_loss_history__{plot_legend_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_parameter_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_accuracy_history in enumerate(plot_different_parameter_train_accuracy_history):\n",
    "        plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_accuracy_history in enumerate(plot_different_parameter_test_accuracy_history):\n",
    "        plt.plot(plot_test_accuracy_history, label=f\"Test Accuracy History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Accuracy\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History\" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_accuracy_history__{plot_legend_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_parameter_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_error_history in enumerate(plot_different_parameter_train_error_history):\n",
    "        plt.plot(plot_train_error_history, label=f\"Train Error History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_error_history in enumerate(plot_different_parameter_test_error_history):\n",
    "        plt.plot(plot_test_error_history, label=f\"Test Error History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Error\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History\" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_error_history__{plot_legend_strings}_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot for Batchsize-Accuracy curve.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batchsize_list = [1]\n",
    "plot_save_fig_bool = False\n",
    "plot_show_train_bool = True\n",
    "plot_show_test_bool = False\n",
    "plot_log_scale = False\n",
    "\n",
    "plot_different_parameter_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_parameter_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "plot_batchsize_accuracy_point_train = []\n",
    "plot_batchsize_accuracy_point_test = []\n",
    "if plot_show_train_bool is True:\n",
    "    for plot_train_accuracy_history in plot_different_parameter_train_accuracy_history:\n",
    "        plot_batchsize_accuracy_point_train.append(plot_train_accuracy_history[-1])\n",
    "    plt.plot(plot_batchsize_list, plot_batchsize_accuracy_point_train, marker='o', linestyle='-', label=f\"Batchsize vs Train Accuracy\")\n",
    "if plot_show_test_bool is True:\n",
    "    for plot_test_accuracy_history in plot_different_parameter_test_accuracy_history:\n",
    "        plot_batchsize_accuracy_point_test.append(plot_test_accuracy_history[-1])\n",
    "    plt.plot(plot_batchsize_list, plot_batchsize_accuracy_point_test, marker='x', linestyle='-', label=f\"Batchsize vs Test Accuracy\")\n",
    "plt.xlabel(\"Batchsize\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Accuracy\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Batchsize-Accuracy History\")\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_batchsize_accuracy_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot for Batchsize-Runtime curve.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batchsize_list = [1]\n",
    "plot_save_fig_bool = False\n",
    "plot_log_scale = False\n",
    "\n",
    "plot_different_parameter_time_history = convert_to_list(data_time_history_total)\n",
    "plot_batchsize_runtime_point = []\n",
    "for plot_time_history in plot_different_parameter_time_history:\n",
    "    plot_batchsize_runtime_point.append(plot_time_history[-1])\n",
    "plt.plot(plot_batchsize_list, plot_batchsize_runtime_point, marker='o', linestyle='-', label=f\"Batchsize vs Runtime\")\n",
    "plt.xlabel(\"Batchsize\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Runtime\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Runtime\")\n",
    "plt.title(\"Batchsize-Runtime History\")\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_batchsize_runtime_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
